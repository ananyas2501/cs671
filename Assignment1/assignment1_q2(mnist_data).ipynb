{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment1_q2(mnist_data).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJXGj8qRiUFYx2O6V91JG5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divgup/cs671/blob/master/assignment1_q2(mnist_data).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GWMry5KqMBK",
        "colab_type": "code",
        "outputId": "157a5a3f-29b3-4b39-84eb-4a9690855bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "#X_train_orig is a 3-D array containing the pixel values of grey image\n",
        "#Y_train_orig is 1-D array containing labels of corresponding image \n",
        "#similarily for X_test and Y_test \n",
        "(X_train_orig,Y_train_orig),(X_test_orig,Y_test_orig) = mnist.load_data()\n",
        "#reshape to a column vector\n",
        "print(Y_train_orig.shape)\n",
        "Y_tr_resh = Y_train_orig.reshape(60000,1)\n",
        "Y_te_resh = Y_test_orig.reshape(10000,1)\n",
        "\n",
        "#one hot encoding to give a 2-D array of size (60000,10) and (10000,10) for training and testing set resp.\n",
        "Y_tr_T = to_categorical(Y_tr_resh,num_classes=10)\n",
        "Y_te_T = to_categorical(Y_te_resh,num_classes=10)\n",
        "Y_train = Y_tr_T.T\n",
        "Y_test = Y_te_T.T\n",
        "print(Y_train.shape)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000,)\n",
            "(10, 60000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOsNUQ5Ht8LC",
        "colab_type": "code",
        "outputId": "4a7f9d22-cb89-4659-9c53-319d9984d054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_flat = X_train_orig.reshape(X_train_orig.shape[0],-1).T\n",
        "X_test_flat = X_test_orig.reshape(X_test_orig.shape[0],-1).T\n",
        "X_train = X_train_flat/255.\n",
        "X_test = X_test_flat/255.\n",
        "print(X_train_flat.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLw289b0Yc9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(a):\n",
        "  return np.exp(a)/(np.sum(np.exp(a),axis=0,keepdims=True))\n",
        "def Relu(u):\n",
        "  u[u<0] = 0\n",
        "  return u  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuFw7zaAELxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {}\n",
        "def initialisation():\n",
        "  #hardcoded the no. of units in each layer\n",
        "  layers = [784,50,50,10]\n",
        "  for it in range(1,len(layers)):\n",
        "    parameters[\"w\"+str(it)] = np.random.rand(layers[it-1],layers[it])*np.sqrt(2/layers[it-1])\n",
        "    parameters[\"b\"+str(it)] = np.zeros((layers[it],1))\n",
        "  #print(parameters[\"w2\"].shape)\n",
        "  #print(weights[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCydTObpGrXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initialisation()\n",
        "print(parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeonPNv6awXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_loss(Y_train,output):\n",
        "  loss = np.sum(np.sum(-Y_train*np.log(output),axis=0,keepdims=True),axis=1,keepdims=True)\n",
        "  return loss/Y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzSsJNM-ItnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer = {}\n",
        "def forward_pass(x,num_layers):\n",
        "  for it in range(num_layers-1):\n",
        "    #print(parameters[\"w\"+str(it+1)].shape)\n",
        "    layer[\"pre_hid\"+str(it+1)] = np.dot(parameters[\"w\"+str(it+1)].T,x)+parameters[\"b\"+str(it+1)]\n",
        "    #print(layer)\n",
        "    if it < num_layers-2:\n",
        "      layer[\"activated\"+str(it+1)] = Relu(layer[\"pre_hid\"+str(it+1)])\n",
        "    else:\n",
        "      #print(layer[\"pre_hid\"+str(it+1)])\n",
        "      layer[\"activated\"+str(it+1)] = softmax(layer[\"pre_hid\"+str(it+1)])\n",
        "      #print(layer[\"activated\"+str(it+1)])\n",
        "    x = layer[\"pre_hid\"+str(it+1)]    \n",
        "    #if it < len(layers)-2):\n",
        "      #x = Relu(l)\n",
        "    #else:\n",
        "      #x = softmax(l)\n",
        "  #return layer      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38VlT1SjlQqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def drelu(x):\n",
        "  y = np.ones(x.shape)\n",
        "  y[x<0] = 0\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSzayZ34OdXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_prop(X_train,num_layers):\n",
        "  output = layer[\"activated\"+str(num_layers-1)]\n",
        "  #print(output.shape)\n",
        "  #print(Y_train.shape)\n",
        "  grad = {}\n",
        "  m = X_train.shape[1]\n",
        "  grad[\"a\"+str(num_layers-1)] = -(Y_train-output)/m\n",
        "  grad[\"h\"+str(num_layers-2)] = np.dot(parameters[\"w\"+str(num_layers-1)],grad[\"a\"+str(num_layers-1)])\n",
        "  #grad[\"w\"+str(len(layers)-1)] = np.dot(output-Y_train,x[pre_hid+str(len(layers)-2)].T)\n",
        "  for it in range(1,num_layers-1):\n",
        "    Indicator = drelu(layer[\"pre_hid\"+str(num_layers-it-1)])\n",
        "    grad[\"a\"+str(num_layers-1-it)] = np.multiply(grad[\"h\"+str(num_layers-it-1)],Indicator) \n",
        "    grad[\"h\"+str(num_layers-it-2)] = np.dot(parameters[\"w\"+str(num_layers-it-1)],grad[\"a\"+str(num_layers-1-it)])\n",
        "  grad[\"w1\"] = np.dot(grad[\"a1\"],X_train.T)\n",
        "  grad[\"b1\"] = np.sum(grad[\"a\"+str(1)],axis=1,keepdims=True)\n",
        "  for it in range(1,num_layers-1):  \n",
        "    grad[\"w\"+str(it+1)] = np.dot(grad[\"a\"+str(it+1)],layer[\"pre_hid\"+str(it)].T) \n",
        "    grad[\"b\"+str(it+1)] = np.sum(grad[\"a\"+str(it+1)],axis=1,keepdims=True)\n",
        "  return grad  \n",
        "  #del_loss_resp_to_h_l0 = np.dot(parameter[\"w2\"],-(Y_train-output))\n",
        "  #pre_hid2 = x[\"pre_hid\"+str(len(layers)-2)]\n",
        "  #i = np.ones(pre_hid2.shape)\n",
        "  #pre_hid1 = x[\"pre_hid\"+str(len(layers)-3)] \n",
        "  #i[pre_hid2<0] = 0\n",
        "  #del_loss_resp_to_al = np.multiply(del_loss_resp_to_h_l0,i)\n",
        "  #del_loss_resp_to_h_l1 = np.dot(paramter[\"w1\"],del_loss_resp_to_al)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5O6cM5Pm8Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_update(num_layers,alpha,grad):\n",
        "  for i in range(num_layers-1):\n",
        "    parameters[\"w\"+str(num_layers-i-1)] = parameters[\"w\"+str(num_layers-i-1)] - (alpha*grad[\"w\"+str(num_layers-i-1)]).T\n",
        "    parameters[\"b\"+str(num_layers-i-1)] = parameters[\"b\"+str(num_layers-i-1)] - (alpha*grad[\"b\"+str(num_layers-i-1)])\n",
        "  return parameters  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_dKHCthJAlB",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c5aecb84-0ffa-4254-a666-d2bc9c1cc57f"
      },
      "source": [
        "alpha = 0.01\n",
        "num_layers = 4\n",
        "cost=[]\n",
        "num_itr = 3000\n",
        "num_hidden_layers = 2\n",
        "initialisation()\n",
        "forward_pass(X_train,num_layers)\n",
        "\n",
        "#print(layer[\"activated\"+str(num_layers-1)])\n",
        "for it in range(num_itr):\n",
        "  forward_pass(X_train,num_layers)\n",
        "  output = layer[\"activated\"+str(num_layers-1)]\n",
        "  grad = back_prop(X_train,num_layers)\n",
        "  #print(parameters[\"b1\"].shape)\n",
        "  weight_update(num_layers,alpha,grad)\n",
        "  if it%50==0:\n",
        "    cost.append(calc_loss(Y_train,output))\n",
        "    print(calc_loss(Y_train,output))\n",
        "  #print(parameters[\"b1\"].shape)    "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.20441103]]\n",
            "[[2.82638553]]\n",
            "[[2.34099539]]\n",
            "[[2.30852984]]\n",
            "[[2.28095241]]\n",
            "[[2.2093381]]\n",
            "[[2.17421669]]\n",
            "[[2.1193431]]\n",
            "[[2.04853542]]\n",
            "[[1.95537801]]\n",
            "[[1.83449687]]\n",
            "[[1.68444129]]\n",
            "[[1.53312531]]\n",
            "[[1.39205481]]\n",
            "[[1.26827654]]\n",
            "[[1.16471807]]\n",
            "[[1.07944335]]\n",
            "[[1.00884437]]\n",
            "[[0.9493274]]\n",
            "[[0.89827458]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScqWOAlN1tqI",
        "colab_type": "code",
        "outputId": "aceeae28-86b6-4d3d-fb6e-cbd7ae87a40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#print(parameters)\n",
        "output = layer[\"activated\"+str(num_layers-1)]\n",
        "acc = np.sum(np.sum(Y_train*output,axis=0,keepdims=True),axis=1,keepdims=True)/Y_train.shape[1]\n",
        "#def metrics():\n",
        "acc_percentage = acc*100\n",
        "print(acc_percentage)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[50.67899838]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t7ouiI-_Xob",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}
